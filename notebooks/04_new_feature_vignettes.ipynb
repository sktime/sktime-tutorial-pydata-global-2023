{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8aa145",
   "metadata": {},
   "source": [
    "### further 2022-2023 highlights\n",
    "\n",
    "#### Advanced modelling\n",
    "\n",
    "* extended parallelism, including parallel broadcasting to hierarchical data\n",
    "* fully distributional probabilistic forecasts and metrics, skpro\n",
    "* composable time series classifiers, regressors, distances, time series aligners\n",
    "* benchmarking frameworks for comparing estimator performance\n",
    "\n",
    "#### Marketplace and deployment features\n",
    "\n",
    "* estimator search, estimator tags\n",
    "* scikit-base interface for multiple libraries\n",
    "* blueprint serialization and sharing\n",
    "* fitted estimator serialization and sharing\n",
    "* mlflow deployment via custom flavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53820e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37897ca3",
   "metadata": {},
   "source": [
    "# Advanced modelling features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e190cf",
   "metadata": {},
   "source": [
    "## parallelism for multivariate and hierarchical broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad27f6",
   "metadata": {},
   "source": [
    "univariate forecasters broadcast across variables if given multivariate data\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"])\n",
    "\n",
    "forecaster = ARIMA()\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "\n",
    "# forecasters_ is a data frame with fitted ARIMA models\n",
    "# entries are references to individual isntances of ARIMA, per variable\n",
    "forecaster.forecasters_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c0f5a",
   "metadata": {},
   "source": [
    "by default, this is base python loop ... but we can use parallel backend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ARIMA()\n",
    "\n",
    "# let's use joblib loky backend, with 2 workers\n",
    "# parallelization configs are accessed via the scikit-base config interface\n",
    "\n",
    "# backends are set via the backend:parallel config\n",
    "forecaster.set_config(**{\"backend:parallel\": \"loky\"})  # or \"multiprocessing\", or \"dask\" (requires dask)\n",
    "# backend params are set via the backend:parallel:params config\n",
    "forecaster.set_config(**{\"backend:parallel:params\": {\"n_jobs\": 2}})  # passed to joblib.Parallel\n",
    "# for documentation of the config interface, see set_config/get_config docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3914f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit/predict methods are now parallelized\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "forecaster.forecasters_\n",
    "# of course this is more useful for larger data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6010e",
   "metadata": {},
   "source": [
    "same for hierarchical data!\n",
    "\n",
    "hierarchical = multiple time series by hierarchical scope or index, e.g., product line/category\n",
    "\n",
    "(typical: 1.000s of low-level hierarchical categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8444ae",
   "metadata": {},
   "source": [
    "![](./img/hierarchy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046afbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchical_demo_utils import load_product_hierarchy\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=4)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eeca19",
   "metadata": {},
   "source": [
    "sliced at a specific date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e003e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiindex slicing can become important when using hierarchical data!\n",
    "y.loc[(slice(None), slice(None), \"2000-01\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6b441",
   "metadata": {},
   "source": [
    "Like for variables, `sktime` broadcasts simple models to hierarchical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "forecaster.fit(y_train, fh=[1, 2, 3, 4])\n",
    "y_pred = forecaster.predict()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasters_ has fitted ETS models\n",
    "forecaster.forecasters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelization is enabled via the same config interface as for variables\n",
    "# (same backend is used for both variables and instances or hierarchy levels)\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "# backends are set via the backend:parallel config\n",
    "forecaster.set_config(**{\"backend:parallel\": \"loky\"})  # or \"multiprocessing\", or \"dask\" (requires dask)\n",
    "# backend params are set via the backend:parallel:params config\n",
    "forecaster.set_config(**{\"backend:parallel:params\": {\"n_jobs\": 2}})  # passed to joblib.Parallel\n",
    "# for documentation of the config interface, see set_config/get_config docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is faster now!\n",
    "forecaster.fit(y_train, fh=[1, 2, 3, 4])\n",
    "y_pred = forecaster.predict()  # both fit and predict are parallelized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e28c89",
   "metadata": {},
   "source": [
    "also works for:\n",
    "\n",
    "* performance metrics (e.g., multivariate and hierarchical)\n",
    "* transformation and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60ba4d",
   "metadata": {},
   "source": [
    "side note: the same backend parameters are used for:\n",
    "\n",
    "* embarrassingly parallel \"special\" estimators such as grid search, random search\n",
    "* benchmarking and evaluation frameworks, e.g., `evaluate` for forecast benchmarks\n",
    "\n",
    "estimator or function params are called:\n",
    "\n",
    "* `backend`, string selecting backend, e.g., `loky`, `multiprocessing` or `dask`\n",
    "* `backend_params`, dict with params passed to backend, e.g., `joblib.Parallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: parallelizing grid search\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
    "from sktime.split import ExpandingWindowSplitter\n",
    "\n",
    "forecaster = ExponentialSmoothing()\n",
    "\n",
    "cv = ExpandingWindowSplitter(fh=[1,2,3,4,5,6], initial_window=12, step_length=1)\n",
    "param_grid = {\n",
    "    \"sp\": [4, 6, 12],\n",
    "    \"seasonal\": [\"add\", \"mul\"],\n",
    "    \"trend\": [\"add\", \"mul\"],\n",
    "    \"damped_trend\": [True, False],\n",
    "}\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    backend=\"loky\",\n",
    "    backend_params={\"n_jobs\": 2},\n",
    "    verbose=1,\n",
    "    scoring=MeanSquaredError(square_root=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075538a",
   "metadata": {},
   "source": [
    "## probabilistic forecasting, distribution outputs, skpro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall probabilistic forecaster vignette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "\n",
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "y_train = y.iloc[:-12]\n",
    "y_test = y.iloc[-12:]\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = ThetaForecaster(sp=12)\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y_train, fh=fh)\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict()\n",
    "\n",
    "# for probabilistic forecasting:\n",
    "#   call a probabilistic forecasting method after or instead of step 5\n",
    "y_pred_int = forecaster.predict_interval(coverage=0.9)\n",
    "y_pred_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fa1f8",
   "metadata": {},
   "source": [
    "**probabilistic forecasting methods in `sktime`**:\n",
    "\n",
    "* forecast intervals    - `predict_interval(fh=None, X=None, coverage=0.90)`\n",
    "* forecast quantiles    - `predict_quantiles(fh=None, X=None, alpha=[0.05, 0.95])`\n",
    "* forecast variance     - `predict_var(fh=None, X=None, cov=False)`\n",
    "* distribution forecast - `predict_proba(fh=None, X=None, marginal=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bca8eb",
   "metadata": {},
   "source": [
    "distribution forecasts have been reworked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b974b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distr = forecaster.predict_proba()\n",
    "y_pred_distr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8db29d",
   "metadata": {},
   "source": [
    "scikit-base distribution object, first class citizen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distr.get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d74bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distr.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a3fb4",
   "metadata": {},
   "source": [
    "pandas-like interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533600b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_subset = y_pred_distr.iloc[[0, 1, 2]]\n",
    "y_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f482fab",
   "metadata": {},
   "source": [
    "distribution-defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e456ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_df = pd.DataFrame([1, 1, 1], index=y_subset.index, columns=y_subset.columns)\n",
    "y_subset.pdf(x_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bdfe0",
   "metadata": {},
   "source": [
    "works seamlessly with probabilistic metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting.probabilistic import CRPS\n",
    "\n",
    "crps = CRPS()\n",
    "\n",
    "crps(y_test, y_pred_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62bf6b",
   "metadata": {},
   "source": [
    "same interface also available for scikit-learn tabular regressors, with `skpro`!\n",
    "\n",
    "see [sktime tutorial at pydata Amsterdam 2023](https://github.com/sktime/sktime-tutorial-pydata-Amsterdam-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a808cd",
   "metadata": {},
   "source": [
    "## modular time series distances, classifiers, aligners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56d22f",
   "metadata": {},
   "source": [
    "Rich component relationships between object types!\n",
    "\n",
    "* many classifiers, regressors, clusterers use distances or kernels\n",
    "* distances and kernels are often composite, e.g., sum-of-distance, independent distance\n",
    "* TS distances are often based on scalar multivariate distances (e.g., Euclidean)\n",
    "* TS distances are often based on alignment, TS aligners are an estimator type!\n",
    "* aligners internally typically use scalar uni/multivariate distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beddfe65",
   "metadata": {},
   "source": [
    "example:\n",
    "\n",
    "* 1-nn using `sklearn` nearest neighbors\n",
    "* with multivariate dynamic time warping distance, from `dtw-python` library \n",
    "* on multivariate `\"mahalanobis\"` distance from `scipy`\n",
    "* in `sktime` compatible interface, constructed from custom components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f92f0b8",
   "metadata": {},
   "source": [
    "so, conceptually:\n",
    "\n",
    "* we build an sequence alignment algorithm (`dtw-python`) using `scipy` Mahalanobis dist\n",
    "* we get the distance matrix computation from alignment algorithm\n",
    "* we use that distance matrix in `sklearn` knn\n",
    "* together this is a time series classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.alignment.dtw_python import AlignerDTWfromDist\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_from_align import DistFromAligner\n",
    "from sktime.dists_kernels.scipy_dist import ScipyDist\n",
    "\n",
    "# Mahalanobis distance on R^n\n",
    "mahalanobis_dist = ScipyDist(metric=\"mahalanobis\")  # uses scipy distances\n",
    "\n",
    "# pairwise multivariate aligner from dtw-python with Mahalanobis distance\n",
    "mw_aligner = AlignerDTWfromDist(mahalanobis_dist)  # uses dtw-python\n",
    "\n",
    "# turning this into alignment distance on time series\n",
    "dtw_dist = DistFromAligner(mw_aligner)  # interface mutation to distance\n",
    "\n",
    "# and using this distance in a k-nn classifier\n",
    "clf = KNeighborsTimeSeriesClassifier(distance=dtw_dist)  # uses sklearn knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3f32a",
   "metadata": {},
   "source": [
    "works seamlessly with `get_params`, `set_params` for tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1097cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41bf49",
   "metadata": {},
   "source": [
    "all object types are first class citizens in sktime!\n",
    "\n",
    "* `\"transformer-panel\"` - time series distances, kernels, pairwise transformers on panel data\n",
    "* `\"transformer-pairwise\"` for all pairwise transformers on tabular data, e.g., scalar distance\n",
    "* `\"aligner\"` for all time series aligners\n",
    "* `\"transformer\"` for all transformers, these can be composed with all the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"transformer-pairwise-panel\", as_dataframe=True, return_tags=[\"pwtrafo_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"aligner\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a40f3",
   "metadata": {},
   "source": [
    "see [sktime tutorial at pydata London 2023](https://github.com/sktime/sktime-tutorial-pydata-london-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfeb82e",
   "metadata": {},
   "source": [
    "## Benchmarking - comparing estimator performance\n",
    "\n",
    "the `benchmarking` module allows you to set up experiments to:\n",
    "\n",
    "* compare the performance of one or more algorithms\n",
    "* over one or multiple datasets\n",
    "* against one or multiple performance metrics\n",
    "* for a benchmark configuration defined by temporal resampling scheme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018330af",
   "metadata": {},
   "source": [
    "`sktime`'s `benchmarking` module is designed to:\n",
    "\n",
    "* provide a high-level specification language\n",
    "* prevent mistakes by abstracting away \"dangerous\" implementation details\n",
    "* allow reproducible sharing of experiment setups and results\n",
    "\n",
    "Any `sktime` compatible object can be plugged in!\n",
    "\n",
    "Use `sktime` extension templates to add custom objects to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1516977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.benchmarking.forecasting import ForecastingBenchmark\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredPercentageError\n",
    "\n",
    "# set up benchmark\n",
    "benchmark = ForecastingBenchmark()\n",
    "\n",
    "# add competing estimators\n",
    "benchmark.add_estimator(\n",
    "    estimator=NaiveForecaster(strategy=\"mean\", sp=12),\n",
    "    estimator_id=\"NaiveForecaster-mean-v1\",\n",
    ")\n",
    "benchmark.add_estimator(\n",
    "    estimator=NaiveForecaster(strategy=\"last\", sp=12),\n",
    "    estimator_id=\"NaiveForecaster-last-v1\",\n",
    ")\n",
    "\n",
    "# define tasks, for forecasting:\n",
    "# backtesting schema, cv splitter, scorer, data\n",
    "cv_splitter = ExpandingWindowSplitter(\n",
    "    initial_window=24,\n",
    "    step_length=12,\n",
    "    fh=12,\n",
    ")\n",
    "scorers = [MeanSquaredPercentageError()]\n",
    "dataset_loaders = [load_airline]\n",
    "\n",
    "# add task\n",
    "for dataset_loader in dataset_loaders:\n",
    "    benchmark.add_task(\n",
    "        dataset_loader,\n",
    "        cv_splitter,\n",
    "        scorers,\n",
    "    )\n",
    "\n",
    "# run the experiment, write to csv\n",
    "results_df = benchmark.run(\"./forecasting_results.csv\")\n",
    "results_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b460b0",
   "metadata": {},
   "source": [
    "for forecasting, use `evaluate` utility for smaller runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79797d2b",
   "metadata": {},
   "source": [
    "see [sktime tutorial at pycon Prague 2023](https://github.com/sktime/sktime-tutorial-pydata-global-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab92a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd55181",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Marketplace and deployment features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbd704",
   "metadata": {},
   "source": [
    "* estimator search, estimator tags\n",
    "* scikit-base interface\n",
    "* blueprint serialization and sharing\n",
    "* fitted estimator serialization and sharing\n",
    "* mlflow deployment via custom flavour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f77c01",
   "metadata": {},
   "source": [
    "## listing estimators, estimator search, estimator tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b55b1d",
   "metadata": {},
   "source": [
    "* all objects now \"first class citizens\" with a type - scikit-base objects\n",
    "* use `all_estimators` for search subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85459607",
   "metadata": {},
   "source": [
    "example: list all forecasters (`sktime` native scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95139a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc8d60",
   "metadata": {},
   "source": [
    "or, list all splitters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbed856",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimators(\"splitter\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500072a9",
   "metadata": {},
   "source": [
    "all classes, objects come with tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class tags\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "ARIMA.get_class_tags()\n",
    "# interesting for users:\n",
    "# object_type tells us this is a forecaster\n",
    "# capability tags, e.g., \"capability:insample\", \"capability:pred_int\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object tags\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "NaiveForecaster().get_tags()\n",
    "# same tags\n",
    "# values may depend on the object parameters, e.g., \"handles-missing-data\"\n",
    "# class tags are \"most general\" capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076854dc",
   "metadata": {},
   "source": [
    "produce table with class tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "# list all forecasters, in a table, with two added columns\n",
    "# capability:insample - can produce in-sample forecasts?\n",
    "# capability:pred_int - can produce prediction intervals?\n",
    "all_estimators(\n",
    "    \"forecaster\", as_dataframe=True, return_tags=[\"capability:insample\", \"capability:pred_int\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80231644",
   "metadata": {},
   "source": [
    "filter for class tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all forecasters that can produce probabilistic forecasts\n",
    "all_estimators(\n",
    "    \"forecaster\", as_dataframe=True, filter_tags={\"capability:pred_int\": True}\n",
    ")\n",
    "# of course you can do this with simple pandas filtering too,\n",
    "# or anything else you want to do with pandas, but it avoids tedious wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0cc68",
   "metadata": {},
   "source": [
    "roadmap, contribute!\n",
    "\n",
    "* easy way to specify variable scope across packages, 1st, 2nd, and 3rd party\n",
    "* updating estimator overview frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1750d80",
   "metadata": {},
   "source": [
    "## sharing model blueprints and fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ba3ae",
   "metadata": {},
   "source": [
    "how to share these with your friends?\n",
    "\n",
    "* model blueprint specs, e.g., equivalent of spec `Pipeline([(\"foo\", Foo()), (\"bar\", Bar(42))])`\n",
    "* fitted models, e.g., state of `my_pipe.fit(y)` after the `fit` - specific to data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d16ee8",
   "metadata": {},
   "source": [
    "### sharing model blueprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d733376",
   "metadata": {},
   "source": [
    "blueprint specs can be serialized using simple string print - this contains all information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40207180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define an example pipeline\n",
    "from sktime.forecasting.compose._pipeline import TransformedTargetForecaster\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "pipe = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"imputer\", Imputer()),\n",
    "        (\"forecaster\", NaiveForecaster()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0991da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the pipeline to a string\n",
    "# this is useful for logging and sharing\n",
    "# pipe_str can be saved to a file, database, or shared over the internet\n",
    "pipe_str = str(pipe)\n",
    "pipe_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27604a73",
   "metadata": {},
   "source": [
    "for pseudo-random determinism, set any `random_state` parameters in the estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec360734",
   "metadata": {},
   "source": [
    "to deserialize, use `registry.craft` in the same python environment\n",
    "\n",
    "for python environment, e.g., use `pip freeze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import craft\n",
    "\n",
    "pipe_new = craft(pipe_str)\n",
    "pipe_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfffddf",
   "metadata": {},
   "source": [
    "this is the same estimator blueprint as `pipe`!\n",
    "\n",
    "To compare blueprint, simply use the `==` operator (this is a `scikit-base` feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_new == pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7ed2a",
   "metadata": {},
   "source": [
    "sharing process:\n",
    "\n",
    "* origin shares `pipe_str = str(pipe)` or `str(my_estimator)` and `pip freeze > requirements.txt` output\n",
    "* recipient installs env from `requirements.txt` and runs `craft(pipe_str)` in that env\n",
    "\n",
    "For custom estimators, in addition, the custom module needs to be shared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0672d7",
   "metadata": {},
   "source": [
    "Highly complex estimators can consist of multiple definition blocks - this is also supported by `craft` as follows.\n",
    "\n",
    "Instead of a string conversion, we can also serialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b721f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_spec is a string representation of the pipeline\n",
    "# it can be stored in a file or a database like this\n",
    "# the \"return\" statement indicates which object we store\n",
    "# temporary variables like pipe, cv can be defined\n",
    "pipe_spec = \"\"\"\n",
    "pipe = TransformedTargetForecaster(steps=[\n",
    "    (\"imputer\", Imputer()),\n",
    "    (\"forecaster\", NaiveForecaster())])\n",
    "cv = ExpandingWindowSplitter(\n",
    "    initial_window=24,\n",
    "    step_length=12,\n",
    "    fh=[1, 2, 3])\n",
    "\n",
    "return ForecastingGridSearchCV(\n",
    "    forecaster=pipe,\n",
    "    param_grid=[{\n",
    "        \"forecaster\": [NaiveForecaster(sp=12)],\n",
    "        \"forecaster__strategy\": [\"drift\", \"last\", \"mean\"],\n",
    "    },\n",
    "    {\n",
    "        \"imputer__method\": [\"mean\", \"drift\"],\n",
    "        \"forecaster\": [ThetaForecaster(sp=12)],\n",
    "    },\n",
    "    {\n",
    "        \"imputer__method\": [\"mean\", \"median\"],\n",
    "        \"forecaster\": [ExponentialSmoothing(sp=12)],\n",
    "        \"forecaster__trend\": [\"add\", \"mul\"],\n",
    "    },\n",
    "    ],\n",
    "    cv=cv,\n",
    "    n_jobs=-1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d58a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "craft(pipe_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5019fa",
   "metadata": {},
   "source": [
    "some estimators require soft dependencies to be installed at `craft`\n",
    "\n",
    "query required dependencies can *before* construction via `deps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import deps\n",
    "\n",
    "deps(pipe_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc98de",
   "metadata": {},
   "source": [
    "(if `pip freeze` is not ehough)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87929231",
   "metadata": {},
   "source": [
    "`imports` can be used to print a full import block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import imports\n",
    "\n",
    "imports(pipe_spec)  # the result can be copied above the spec in to a jupyter cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39fe09",
   "metadata": {},
   "source": [
    "### Persisting fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab450c88",
   "metadata": {},
   "source": [
    "to persist a fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "\n",
    "y = load_airline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a159e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example pipeline\n",
    "from sktime.forecasting.compose._pipeline import TransformedTargetForecaster\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "pipe = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"imputer\", Imputer()),\n",
    "        (\"forecaster\", NaiveForecaster()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(y, fh=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a47e1",
   "metadata": {},
   "source": [
    "to serialize fitted objects, use `save` - default is `pkl`, but may differ for deep learning\n",
    "\n",
    "* no args produces in-memory object\n",
    "* `str` or `Path` arg will serialize to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20bdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mem = pipe.save()\n",
    "# pipe_mem is a pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0889ecc",
   "metadata": {},
   "source": [
    "to deserialize use the `load` method on the memory object or a `str`, `Path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.base import load\n",
    "\n",
    "pipe_new = load(pipe_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255919c",
   "metadata": {},
   "source": [
    "the loaded object can be used for prediction now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_new.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89327329",
   "metadata": {},
   "source": [
    "for more, see [sktime tutorial at pycon Prague 2023](https://github.com/sktime/sktime-tutorial-pydata-global-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a94791",
   "metadata": {},
   "source": [
    "### mlflow custom flavour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071aa452",
   "metadata": {},
   "source": [
    "with `mlflow` / `mlflavors`:\n",
    "\n",
    "* use `mlflow` context manager `start_run`\n",
    "* results are logged/saved using standard `mlflow.log_params`, `log_metrics`\n",
    "* model is logged/saved using `mlflavors.sktime.log_model`\n",
    "\n",
    "for further use (load), get artefact URI using `get_artifact_uri`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6724b",
   "metadata": {},
   "source": [
    "Example: save fitted model, model parameters, and results of this experiment to server\n",
    "\n",
    "* fit `NaiveForecaster` on longley data (with exogenous vars)\n",
    "* evaluate via MAE and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import mlflavors\n",
    "import mlflow\n",
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "\n",
    "ARTIFACT_PATH = \"model\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    y, X = load_longley()\n",
    "    y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)\n",
    "\n",
    "    forecaster = NaiveForecaster()\n",
    "    forecaster.fit(\n",
    "        y_train,\n",
    "        X=X_train,\n",
    "        fh=[1, 2, 3, 4],\n",
    "    )\n",
    "\n",
    "    # Extract parameters\n",
    "    parameters = forecaster.get_params()\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = forecaster.predict(X=X_test)\n",
    "    metrics = {\n",
    "        \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    print(f\"Parameters: \\n{json.dumps(parameters, indent=2)}\")\n",
    "    print(f\"\\nMetrics: \\n{json.dumps(metrics, indent=2)}\")\n",
    "\n",
    "    # Log parameters and metrics\n",
    "    mlflow.log_params(parameters)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log model to MLflow tracking server\n",
    "    mlflavors.sktime.log_model(\n",
    "        sktime_model=forecaster,\n",
    "        artifact_path=ARTIFACT_PATH,\n",
    "    )\n",
    "    \n",
    "    # Return model uri from the current run\n",
    "    model_uri = mlflow.get_artifact_uri(ARTIFACT_PATH)\n",
    "    \n",
    "# Print the run id wich is used below for serving the model to a local REST API endpoint\n",
    "print(f\"\\nMLflow run id:\\n{run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5482f9",
   "metadata": {},
   "source": [
    "loading via `load_model` (below) or `pyfunc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflavors.sktime.load_model(model_uri=model_uri)\n",
    "print(loaded_model.predict_interval(fh=[1, 2, 3], X=X_test, coverage=[0.9, 0.95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effae1e",
   "metadata": {},
   "source": [
    "see [sktime tutorial at ODSC Europe 2023](https://github.com/sktime/sktime-tutorial-ODSC-Europe-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9180220",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f15725",
   "metadata": {},
   "source": [
    "### 2022-2023 highlights seen today\n",
    "\n",
    "#### Forecasting\n",
    "\n",
    "* streamlined interface\n",
    "* pipelines introduction\n",
    "* new: graphical pipeline\n",
    "\n",
    "#### Advanced modelling\n",
    "\n",
    "* extended parallelism, including parallel broadcasting to hierarchical data\n",
    "* fully distributional probabilistic forecasts and metrics, skpro\n",
    "* composable time series classifiers, regressors, distances, time series aligners\n",
    "* benchmarking frameworks for comparing estimator performance\n",
    "\n",
    "#### Marketplace and deployment features\n",
    "\n",
    "* estimator search, estimator tags\n",
    "* scikit-base interface for multiple libraries\n",
    "* blueprint serialization and sharing\n",
    "* fitted estimator serialization and sharing\n",
    "* mlflow deployment via custom flavour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Credits:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
